__global__ void PDH_kernel2(bucket* d_histogram, 
							double* d_atom_x_list, double* d_atom_y_list, double * d_atom_z_list, 
							long long acnt, double res, int M)
{
	//our location in the global atom list
	int id = blockIdx.x*blockDim.x + threadIdx.x;

	//load our single data point
	double x1 = d_atom_x_list[id];
	double y1 = d_atom_y_list[id];
	double z1 = d_atom_z_list[id];
	double x2,y2,z2;
	int i, j, h_pos;
	double dist;

	
	//once we're sure this much is correct, we'll work out making it dynamically sizeable
	//BLOCK_COUNT = 256
	//to access the x(0) component, the y(1) component, and the z(2) component, do tid + blockdim*axes
	extern __shared__ double Rblock[];
	 
	 //small debug logic
	//interblock for loop, for the M value, use the grid's dimensions
	for(i = blockIdx.x+1; i < M; i++)
	{

		Rblock[threadIdx.x] = 	                d_atom_x_list[blockDim.x*i + threadIdx.x];
		Rblock[threadIdx.x + BLOCK_SIZE] = 	    d_atom_y_list[blockDim.x*i + threadIdx.x];
		Rblock[threadIdx.x + BLOCK_SIZE*2] = 	d_atom_z_list[blockDim.x*i + threadIdx.x];

		__syncthreads();
		for(j = 0; j < blockDim.x; j++)
		{
			//this func
			x2 = Rblock[j];
			y2 = Rblock[j + BLOCK_SIZE];
			z2 = Rblock[j + BLOCK_SIZE*2];
			dist = sqrt((x1 - x2)*(x1-x2) + (y1 - y2)*(y1 - y2) + (z1 - z2)*(z1 - z2));
			h_pos = (int)(dist/res);
			// if(threadIdx.x == 0)
			// 	printf("hpos: %d",h_pos);
			atomicAdd((unsigned long long int*)&d_histogram[h_pos].d_cnt,1);
			
		}
		__syncthreads();
	}

	//intrablock for loop
	Rblock[threadIdx.x] = 	d_atom_x_list[id];
	Rblock[threadIdx.x + BLOCK_SIZE] = 	d_atom_y_list[id];
	Rblock[threadIdx.x + BLOCK_SIZE*2] = 	d_atom_z_list[id];

	__syncthreads();
	for(i = threadIdx.x +1; i < blockDim.x; i++)
	{
		//this func
		x2 = Rblock[j];
		y2 = Rblock[j +BLOCK_SIZE];
		z2 = Rblock[j +BLOCK_SIZE*2];
		dist = sqrt((x1 - x2)*(x1-x2) + (y1 - y2)*(y1 - y2) + (z1 - z2)*(z1 - z2));
		//atomic add
		h_pos = (int)(dist/res);
		atomicAdd((unsigned long long int*)&d_histogram[h_pos].d_cnt,1);
	}


	//write output back to histogram... not yet! we havent gotten to the privatized histogram yet!
	//__syncthreads();
}



//M = Grid Size = total number of blocks
	//B = Block Size
	int t = threadIdx.x;
	int b = blockIdx.x;
	int reg = t * B*b;
	int i, j, h_pos;
	double x1, y1, z1;
	double x2, y2, z2;
	double d;
	

	//make sure we are a valid atom in the array
	if(reg < acnt) 
	{

		x1 = d_atom_x_list[reg];
		y1 = d_atom_y_list[reg];
		z1 = d_atom_z_list[reg];

		for(i = b+1; i < M; i++)
		{
			// R[t + BLOCK_SIZE*0] = d_atom_x_list[t + i*B];
			// R[t + BLOCK_SIZE*1] = d_atom_y_list[t + i*B];
			// R[t + BLOCK_SIZE*2] = d_atom_z_list[t + i*B];
				
			R[3*t + 0] = d_atom_x_list[t + i*B];
			R[3*t + 1] = d_atom_y_list[t + i*B];
			R[3*t + 2] = d_atom_z_list[t + i*B];

			__syncthreads();

			for(j = 0; j < B; j++)
			{
				
				// x2 = R[j + BLOCK_SIZE*0];
				// y2 = R[j + BLOCK_SIZE*1];
				// z2 = R[j + BLOCK_SIZE*2];

				x2 = R[3*j + 0];
				y2 = R[3*j + 1];
				z2 = R[3*j + 2];
				d = sqrt((x1-x2)*(x1-x2) + (y1-y2)*(y1-y2) + (z1-z2)*(z1-z2));
				h_pos = (int) (d/res);
				// atomicAdd(&d_histogram[h_pos].d_cnt, 1);
				atomicAdd(&d_histogram[h_pos], 1);
			
			}
			__syncthreads();
			
		}

		// R[t + BLOCK_SIZE*0] = d_atom_x_list[reg];
		// R[t + BLOCK_SIZE*1] = d_atom_y_list[reg];
		// R[t + BLOCK_SIZE*2] = d_atom_z_list[reg];
		R[3*t + 0] = d_atom_x_list[reg];
		R[3*t + 1] = d_atom_y_list[reg];
		R[3*t + 2] = d_atom_z_list[reg];
		__syncthreads();

		for(i = t+1; i < B; i++)
		{
			// x2 = R[i + BLOCK_SIZE*0];
			// y2 = R[i + BLOCK_SIZE*1];
			// z2 = R[i + BLOCK_SIZE*2];

			x2 = R[3*i + 0];
			y2 = R[3*i + 1];	
			z2 = R[3*i + 2];	

			d = sqrt((x1-x2)*(x1-x2) + (y1-y2)*(y1-y2) + (z1-z2)*(z1-z2));
			h_pos = (int) (d/res);
			atomicAdd(&d_histogram[h_pos], 1);
		}
		__syncthreads();
	}





	__device__ double p2p_dist_kern(int i, int j, double* sharedMem, int blockSize)
{
	double x1 = sharedMem[i];
	double x2 = sharedMem[j];
	double y1 = sharedMem[i];
	double y2 = sharedMem[j];
	double z1 = sharedMem[i];
	double z2 = sharedMem[j];
	return sqrt((x1 - x2)*(x1-x2) + (y1 - y2)*(y1 - y2) + (z1 - z2)*(z1 - z2));
}


//note: for right now, we are trying to make this kernel work for the 'ideal' case of 64 blocks, and 6400 points, leading to a 512 byte size block shared buffer per axis
//      this means we are doing no bounds checking! once this works, add that back in!
//   update: now this seems like its working. though there's more differences than I care for
__global__ void PDH_kernel2(unsigned long long* d_histogram, 
							double* d_atom_x_list, double* d_atom_y_list, double * d_atom_z_list, 
							long long acnt, double res,
							 int numBlocks, int blockSize)
{
	extern __shared__ double LR[];	
							//the size of this should be 3*BLOCK_SIZE*sizeof(double), to house the three arrays in shared memory
							//where t is a specific index into the 'atom' array
							//
							//the rth x array should be accessed by LR[t + 3*BLOCK_SIZE]				
							//the rth y array should be accessed by LR[t + BLOCK_SIZE + 3*BLOCK_SIZE]	
							//the rth z array should be accessed by LR[t + BLOCK_SIZE*2 + 3*BLOCK_SIZE]
							//the lth x array should be accessed by LR[t]
							//the lth y array should be accessed by LR[t + BLOCK_SIZE]
							//the lth z array should be accessed by LR[t + BLOCK_SIZE*2]
	int id = blockIdx.x * blockDim.x + threadIdx.x;
	int i, j, h_pos;
	int i_id;
	int t = threadIdx.x;
	double x1, y1, z1, x2, y2, z2;
	double dist;
	if(id < acnt)
	{

		LR[t] = d_atom_x_list[id];
		LR[t + blockSize] = d_atom_y_list[id];
		LR[t + blockSize*2] = d_atom_z_list[id];

		for(i = blockIdx.x + 1; i < numBlocks; i++)
		{
			i_id = i * blockDim.x + t;
			//although this is more accurate than before, I am likely not handling the case
			//where there is 'some of a valid block'
			//that is, once again, edge cases are creeping in to prevent me from performing p2pdist on ALL possible points
			//because i_id can only check at the block and thread level, i dont have a way to be more granular here
			//this means the inner for loop probably cannot run for all possible points
			//for the most part, this is much closer than before, so we'll keep continuing with the optimizing
			//and then we will come back to make this fully correct
			if(i_id < acnt)
			{
				LR[t + 3*blockSize] = 				d_atom_x_list[i_id];
				LR[t + blockSize + 3*blockSize] = 	d_atom_y_list[i_id];
				LR[t + blockSize*2 + 3*blockSize]=  d_atom_z_list[i_id];
				__syncthreads();

				for(j = 0; j < blockSize; j++)
				{
					//grab L from shared memory
					x1 = LR[t];
					y1 = LR[t + blockSize];
					z1 = LR[t + blockSize*2];

					//grab R from shared memory
					x2 = LR[j + 3*blockSize];
					y2 = LR[j + blockSize + 3*blockSize];
					z2 = LR[j + blockSize*2 + 3*blockSize];

					//compute the distance
					// dist = sqrt(pow(x1 - x2, 2.0) + pow(y1-y2, 2.0) + pow(z1-z2, 2.0));
					dist = sqrt((x1 - x2)*(x1-x2) + (y1 - y2)*(y1 - y2) + (z1 - z2)*(z1 - z2));

					//place into histogram
					h_pos = (int)(dist/res);
					atomicAdd((unsigned long long int*)&d_histogram[h_pos], 1);
				}
			}
		}

		for(i = t+1; i < blockSize; i++)
		{
			//now we just do L against L
			x1 = LR[t];
			y1 = LR[t + blockSize];
			z1 = LR[t + blockSize*2];

			x2 = LR[i];
			y2 = LR[i + blockSize];
			z2 = LR[i + blockSize*2];

			//compute the distance
			// dist = sqrt(pow(x1 - x2, 2.0) + pow(y1-y2, 2.0) + pow(z1-z2, 2.0));
			dist = sqrt((x1 - x2)*(x1-x2) + (y1 - y2)*(y1 - y2) + (z1 - z2)*(z1 - z2));

			//place into histogram
			h_pos = (int)(dist/res);
			atomicAdd((unsigned long long int*)&d_histogram[h_pos], 1);
		}
	}
}

